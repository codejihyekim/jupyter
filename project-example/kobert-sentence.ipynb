{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('./data/train_data.csv')\n",
    "test = pd.read_csv('./data/test_data.csv')\n",
    "sub = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index                                            premise  \\\n",
      "13307  13307     이수역 사건을 두고 산이와 디스 공방을 벌인 제리케이가 대응하지 않겠다고 선언했다.   \n",
      "13870  13870  유배지에서 윤필상이 죽었을 때 그의 시체를 열흘 동안이나 들판에 버려두고 방치하였는...   \n",
      "12381  12381  유씨가 입국 거부와 관련해 법원에 소송을 낸 것은 이번이 처음으로 2002년 국가인...   \n",
      "\n",
      "                             hypothesis          label  \n",
      "13307           산이와 제리케이는 서로 디스를 주고받았다.     entailment  \n",
      "13870                  윤필상은 유배지에서 병사했다.        neutral  \n",
      "12381  유씨가 2002년 국가인권위원회에 낸 진정은 받아들여졌다.  contradiction  \n"
     ]
    }
   ],
   "source": [
    "print(train.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "train = train.dropna(how='any') # Null 값이 존재하는 행 제거\n",
    "train = train.reset_index(drop=True) \n",
    "print(train.isnull().values.any()) # Null 값이 존재하는지 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "test = test.dropna(how='any') # Null 값이 존재하는 행 제거 \n",
    "test = test.reset_index(drop=True)\n",
    "print(test.isnull().values.any()) # Null 값이 존재하는지 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise 최대 길이: 90\n",
      "hypothesis 최대 길이: 103\n",
      "premise 최대 길이: 90\n",
      "hypothesis 최대 길이: 75\n"
     ]
    }
   ],
   "source": [
    "print(\"premise 최대 길이:\", train['premise'].map(len).max())\n",
    "print(\"hypothesis 최대 길이:\", train['hypothesis'].map(len).max())\n",
    "print(\"premise 최대 길이:\", test['premise'].map(len).max())\n",
    "print(\"hypothesis 최대 길이:\", test['hypothesis'].map(len).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index                                            premise  \\\n",
      "200    200                   쏟아지는 빗속에서 길 잃은 새끼고양이 한 마리가 찾아든다.   \n",
      "201    201  또한 저지대와 산사태, 축대 옹벽 등 붕괴 위험지역 예찰을 강화하고 위험 징후 시 ...   \n",
      "202    202                           무엇보다 호스트의 따뜻한 배려에 감동받았다.   \n",
      "203    203                          나쁜의미가 아니라, 각각의 장점들이 존재해요.   \n",
      "204    204                         가족이 머물기에 전반적으로 만족했던 숙소였어요.   \n",
      "205    205   줄 서 있던 시민들과 사진 촬영을 하던 백종원 씨는 대기줄에서 낯익은 얼굴을 발견했다.   \n",
      "206    206                             정말 내가 지내본 숙소 중에 최악입니다.   \n",
      "207    207                            큰 창과 아기자기한 방이 인상적이었습니다.   \n",
      "208    208                        뻔한듯한 내용이지만 대사 한마디가 마음을 울린다.   \n",
      "209    209                    충돌로 가벼운 상처를 입은 강씨 외에는 부상자는 없었다.   \n",
      "210    210                           호스트의 아버지, 어머니는 정말 친절하셨다.   \n",
      "211    211  일본 정부가 지난 27일 폭발한 규슈 지역의 신모에다케 화산 인근 주민들에게 피난 ...   \n",
      "212    212                          장선우 감독과 이정현의 처음이자 마지막의 역작   \n",
      "213    213                              손소독 후 앵무새들을 천천히 살펴봤다.   \n",
      "214    214                          사진으로 보는것 이상으로 깨끗하고 편안합니다.   \n",
      "215    215                            한혜진 씨는 이 주장에 반대 의견을 냈다.   \n",
      "216    216  육아코칭 서비스에 대한 자세한 사항은 부평구 풀뿌리 여성센터 를 참조하거나 전화로 ...   \n",
      "217    217                              최선정 정신병원 입원하는걸로 끝나겠어요   \n",
      "218    218  도입방안에 따라 우선 연료보조금 지급대상은 현행 유가보조금 대상인 노선버스 및 전세...   \n",
      "219    219  전쟁이 끝난 1953년 1인당 국민소득 67불에 불과했던 대한민국이 폐허에서 일어나...   \n",
      "220    220                       하지만 전반적으로 굉장히 만족스러운 숙박이었습니다.   \n",
      "221    221                           방 자체는 정말 깔끔하고 호텔처럼 고급져요.   \n",
      "222    222  방송통신심의위원회 직원이 업무시간에 김영오씨를 대상으로 악플을 쓴 것이 확인되었기 ...   \n",
      "223    223  그러나 오는 15일 인근 지역에 또다시 폭우가 예보되어 있어 최악의 가능성은 배제하...   \n",
      "224    224  이에 맞춰 통신 대기업인 소프트방크가 내년 4월부터 근무시간 중의 흡연을 전면 금지...   \n",
      "225    225  온 나라가 총기 규제 법안으로 떠들썩한 가운데 그녀는 자신의 신념에 따라 모두가 포...   \n",
      "226    226                             우선 숙소는 사진과 동일하고 깔끔합니다.   \n",
      "227    227               아오리 라멘은 유리 홀딩스와의 관계도 정리하기로 했다고 언급했다.   \n",
      "228    228                  자세한 내용은 우리나라 생태관광 이야기에서 확인할 수 있다.   \n",
      "229    229            그러기 위해서 꼭 필요한 것이 서로 고통을 분담하는 사회적 합의입니다.   \n",
      "230    230  스캔론 플랜의 목적은 종업원들의 잠재력을 극대화시켜 작업능률을 향상 시켜 경영성과를...   \n",
      "231    231  그동안 연수생들은 인턴과정을 마친 후 개인적 의지에 따라 국내 취업을 하거나 진학 ...   \n",
      "232    232      상쾌한 아침 날씨는 버턴 지방의 시골에서 보낸 그녀의 젊은 시절을 떠올리게 한다.   \n",
      "233    233  경기 가평군은 올해 만65세 이상 노인에게 지급되는 기초연금의 선정기준이 상향 조정...   \n",
      "234    234  그리고 12월 31일 할머니들과 정신대문제대책협의회 관계자들은 송년회를 열고 더 나...   \n",
      "235    235                              생각보다 단순했지만 나름 흥미진진했어요   \n",
      "236    236  요안나 대사는 세계 유일 유엔군 묘지인 부산 재한유엔기념공원 국제관리위원회의 의장직...   \n",
      "237    237                         이렇게 편리하고 깨끗한 에어비엔비는 처음입니다.   \n",
      "238    238  온실가스진단 상담사가 취약가구에 폭염대응물품을 전달하고 비대면 방식인 유선전화를 최...   \n",
      "239    239  특히 공공미술 사업, 청년 창업 지원 등 지역 특성이 반영된 것과 사업의 실현가능성...   \n",
      "240    240               람세스역이 좀 아쉽긴 해도 대규모의 영상미는 정말 명불허전이었다.   \n",
      "241    241  광고성 정보가 부분적이라는 주장이나 브랜디드 콘텐츠 상단의 해시태그는 법적 기준과는...   \n",
      "242    242  특히 정부는 재학대 상황이 발견되는 경우 학대행위자에 대해 무관용원칙을 적용해 수사...   \n",
      "243    243                            집도 너무 깔끔하고 침대가 정말 편안해요.   \n",
      "244    244  곡성군은 3월부터 12월까지의 활동 결과에 따라 우수한 팀을 선정하여 포상금을 지급...   \n",
      "245    245                       후반부로 갈수록 좀 내용이 복잡해지긴 하는데재밌네요   \n",
      "246    246  양상훈 주필이 해당 발언을 칼럼에 인용한 것에 대해서도 사용의 옳고 그름을 따지기 ...   \n",
      "247    247                          문제는 진단키트마다 기준값이 다르다는 것이다.   \n",
      "248    248                         다만, 중국식 가정집이라는 것을 감안하셔야해요.   \n",
      "249    249                     한국판 뉴딜은, 대한민국 새로운 100년의 설계입니다.   \n",
      "\n",
      "                                            hypothesis          label  \n",
      "200                                길 잃은 새끼고양이를 키우게 된다.        neutral  \n",
      "201                        붕괴가 일어날 수 있는 지역을 잘 살피기로 했다.     entailment  \n",
      "202                       호스트가 비오는 날 우산을 챙겨주셔서 감동적이었다.        neutral  \n",
      "203                      각각의 장점들이 존재한다는 것은 나쁜의미가 아니에요.     entailment  \n",
      "204                                 가족이 머물기에 나쁘지 않았어요.     entailment  \n",
      "205                            백종원 씨는 시민들과 사진을 찍지 않았다.  contradiction  \n",
      "206                            내가 지내본 숙소 중에 가장 더러웠습니다.        neutral  \n",
      "207                                  창과 방 모두 아기자기했습니다.  contradiction  \n",
      "208                                한 마디 제외하고 대사가 평범했다.        neutral  \n",
      "209                                부상을 당한 사람은 강씨 뿐이었다.     entailment  \n",
      "210                                   호스트의 아버지만 친절하셨다.  contradiction  \n",
      "211                             신모에다케 화산이 지난 27일 폭발했다.     entailment  \n",
      "212                                 장선우 감독과 이정현의 작품이다.     entailment  \n",
      "213                                  손소독을 하고 앵무새들을 봤다.     entailment  \n",
      "214                                      사진으로 본 적이 있다.     entailment  \n",
      "215                    한헤진 씨 뿐 아니라 다른 사람들도 이 주장에 반대했다.        neutral  \n",
      "216                            전화로 문의할 경우 자동응답으로 연결된다.        neutral  \n",
      "217                              최선정 정신병원에 입원하면 끝이 난다.     entailment  \n",
      "218                                 유가보조금은 월 10만원 나온다.        neutral  \n",
      "219                                  1953년에 전쟁이 끝났습니다.     entailment  \n",
      "220                                      숙박이 만족스러웠습니다.     entailment  \n",
      "221                                     호텔처럼 고급진 방이예요.     entailment  \n",
      "222                            방송통신심의위원회의 업무시간은 탄력적이다.        neutral  \n",
      "223                       인근 지역에 또 폭우가 내릴 것으로 예보하고 있다.     entailment  \n",
      "224                     소프트방크는 근무시간 외의 흡연을 전면 금지하고 있다.  contradiction  \n",
      "225                             사람들은 총기 규제 법안에 관심이 없다.  contradiction  \n",
      "226                                    사진과 딴판이라 짜증납니다.  contradiction  \n",
      "227                유리 홀딩스 논란 때문에 아오리 라멘이 관계를 정리하기로 했다.        neutral  \n",
      "228                          자세한 내용은 안내책자에서만 확인할 수 있다.  contradiction  \n",
      "229                           고통을 분담하는 사회적합의가 꼭 필요합니다.     entailment  \n",
      "230                             스캔론 플랜의 목적은 경영성과 향상이다.     entailment  \n",
      "231                                연수생의 대부분이 취업에 실패했다.  contradiction  \n",
      "232                        그녀는 버턴 지방의 시골에서 젊은 시절을 보냈다.     entailment  \n",
      "233                    경기 가평군은 기초 연금 선정 기준을 조정했다고 밝혔다.     entailment  \n",
      "234                                   송년회는 할머니들이 주최했다.        neutral  \n",
      "235                                     생각보다 쉽고 재밌었어요.     entailment  \n",
      "236                            유엔군 묘지는 전 세계에 총 8곳이 있다.  contradiction  \n",
      "237                           깨끗하고 불편하지 않은 에어비앤비 였습니다.     entailment  \n",
      "238                    유선전화 뿐 아니라 다른 비대면 방식도 활용할 예정이다.        neutral  \n",
      "239  특히 공공미술 사업, 청년 창업 지원 등 지역 특성이 반영된 것과 사업의 실현가능성...  contradiction  \n",
      "240                                  대규모 전쟁씬이 명불허전이었다.        neutral  \n",
      "241                 브랜디드 콘텐츠 상단의 해시태그는 법적 기준과 관련있지 않다.     entailment  \n",
      "242                첫 학대 상황이 발견될 경우 학대행위자에게 관용원칙이 적용된다.        neutral  \n",
      "243                              집이 너무 깔끔해서 이질감이 들었어요.  contradiction  \n",
      "244                우수한 팀으로 선정되면 곡성군으로부터 인센티브를 받을 수 있다.     entailment  \n",
      "245                               마지막으로 갈수록 내용이 복잡해져요.     entailment  \n",
      "246        양상훈 주필이 해당 발언을 칼럼에 인용한 것은 사회적으로 큰 파장을 일으켰다.        neutral  \n",
      "247                             진단키트마다 기준값이 다른 것이 문제다.     entailment  \n",
      "248                                        일본식 가정집이에요.  contradiction  \n",
      "249                       대한민국의 새로운 백년의 설계는 한국판 뉴딜입니다.     entailment  \n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 100\n",
    "valid = train[100:150]\n",
    "train = train[200:250]\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_name = 'klue/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def convert_examples_to_features(sent_list1,sent_list2, max_seq_len, tokenizer):\n",
    "    input_ids, attention_masks, token_type_ids = [], [], []\n",
    "\n",
    "    for sent1, sent2 in tqdm(zip(sent_list1, sent_list2), total=len(sent_list1)):\n",
    "        encoding_result = tokenizer.encode_plus(sent1, sent2,\n",
    "                                                max_length=max_seq_len, pad_to_max_length=True)\n",
    "        input_ids.append(encoding_result['input_ids'])\n",
    "        attention_masks.append(encoding_result['attention_mask'])\n",
    "        token_type_ids.append(encoding_result['token_type_ids'])\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "\n",
    "    return (input_ids, attention_masks, token_type_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 50/50 [00:00<00:00, 2631.41it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = convert_examples_to_features(train['premise'], train['hypothesis'], \n",
    "                                       max_seq_len=max_seq_len, \n",
    "                                       tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 2757.05it/s]\n"
     ]
    }
   ],
   "source": [
    "X_valid = convert_examples_to_features(valid['premise'], valid['hypothesis'], \n",
    "                                       max_seq_len=max_seq_len, \n",
    "                                       tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1666/1666 [00:00<00:00, 5074.32it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = convert_examples_to_features(test['premise'], test['hypothesis'], \n",
    "                                       max_seq_len=max_seq_len, \n",
    "                                       tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train['label'])\n",
    "y_valid = le.transform(valid['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contradiction': 0, 'entailment': 1, 'neutral': 2}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_idx = dict(zip(list(le.classes_), le.transform(list(le.classes_))))\n",
    "label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "class TFBertForSequenceClassification(Model):\n",
    "    def __init__(self, model_name):\n",
    "        super(TFBertForSequenceClassification, self).__init__()\n",
    "        self.bert = TFAutoModel.from_pretrained(model_name, \n",
    "                                                num_labels=3, \n",
    "                                                from_pt=True)\n",
    "        self.classifier = Dense(3,\n",
    "                                kernel_initializer=TruncatedNormal(0.02),\n",
    "                                activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_ids, attention_mask, token_type_ids=inputs\n",
    "        outputs = self.bert(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask, \n",
    "                            token_type_ids=token_type_ids)\n",
    "        cls_token = outputs[1]\n",
    "        prediction = self.classifier(cls_token)\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = TFBertForSequenceClassification(model_name)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1fab1972ac0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1fab1972ac0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "2/2 [==============================] - ETA: 0s - loss: 1.1214 - accuracy: 0.3800 WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "2/2 [==============================] - 18s 3s/step - loss: 1.1214 - accuracy: 0.3800 - val_loss: 1.2506 - val_accuracy: 0.3600\n",
      "Epoch 2/2\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\", \n",
    "    min_delta=0.001,\n",
    "    patience=2)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs=2, batch_size=32, validation_data=(X_valid, y_valid),\n",
    "    callbacks = [early_stopping]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mibot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78a07efa8151e60bebec4935b6d87f2eb853b7e5bf313c5f08333e63aca22aae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
